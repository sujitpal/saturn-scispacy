{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Paragraphs from JSON Files\n",
    "\n",
    "This notebook reads the CORD-19 dataset for 2020-08-29 (downloaded from [AllenAI's CORD-19 Historical Releases Page](https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/historical_releases.html), expanded and manually copied to S3, as follows:\n",
    "\n",
    "    .\n",
    "    ├── pdf_json\n",
    "    ├── pmc_json\n",
    "    └── metadata.csv\n",
    "\n",
    "The `metadata.csv` is a master list of files, some of which are available in the `pdf_json` and `pmc_json` sub-folders. We parse the JSON files and extract paragraphs (and title sentences) and write them out to a Parquet file for downstream processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import dask.dataframe as dd\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from dask.distributed import Client, progress, get_worker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"saturn-elsevierinc\"\n",
    "FOLDER_NAME = \"cord19\"\n",
    "\n",
    "DATA_FOLDER = \"/\".join([\"s3:/\", BUCKET_NAME, FOLDER_NAME])\n",
    "\n",
    "METADATA_FILE = \"/\".join([\"s3:/\", BUCKET_NAME, FOLDER_NAME, \"metadata.csv\"])\n",
    "\n",
    "PARAGRAPH_FOLDER = \"/\".join([\"s3:/\", BUCKET_NAME, \"cord19-paras-pq-sm\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read metadata file\n",
    "\n",
    "The `metadata.csv` file contains the full list of files. Some of the files don't have full-text associated because of paywall issues, but the `metadata.csv` file contains the title and abstract for them. Files for which full text is provided have the path to the full text referenced in the `pdf_json_files` and `pmc_json_files` columns. \n",
    "\n",
    "Of the files referenced in this dataframe, 140,317 do not have either filepath populated (meaning they don't exist in the dataset), 25,250 have only the `pdf_json_files` column populated, and 4,598 have only the `pmc_json_files` column populated. Our strategy (see cell 7) is to use `pdf_json_files` when available, else use `pmc_json_files`, and discard the record if none are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>pdf_json_files</th>\n",
       "      <th>pmc_json_files</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6498</th>\n",
       "      <td>sz7qmi8q</td>\n",
       "      <td>Interstitielle Lungenerkrankungen</td>\n",
       "      <td>Interstitial pneumonia is a rare disease, posi...</td>\n",
       "      <td>document_parses/pdf_json/cd0e34984d3ba62e544e3...</td>\n",
       "      <td>document_parses/pmc_json/PMC7101537.xml.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33851</th>\n",
       "      <td>4amnl029</td>\n",
       "      <td>Covid-19: Lack of test and trace data are frus...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32210</th>\n",
       "      <td>5moean7z</td>\n",
       "      <td>COVID-19 in Patient with Sarcoidosis Receiving...</td>\n",
       "      <td>Because of in vitro studies, hydroxychloroquin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22958</th>\n",
       "      <td>do0dumkk</td>\n",
       "      <td>We're more negative after five nights of less ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20225</th>\n",
       "      <td>yctuuh7w</td>\n",
       "      <td>Paediatrics in the Tropics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>document_parses/pmc_json/PMC7150102.xml.json</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cord_uid                                              title  \\\n",
       "6498   sz7qmi8q                  Interstitielle Lungenerkrankungen   \n",
       "33851  4amnl029  Covid-19: Lack of test and trace data are frus...   \n",
       "32210  5moean7z  COVID-19 in Patient with Sarcoidosis Receiving...   \n",
       "22958  do0dumkk  We're more negative after five nights of less ...   \n",
       "20225  yctuuh7w                         Paediatrics in the Tropics   \n",
       "\n",
       "                                                abstract  \\\n",
       "6498   Interstitial pneumonia is a rare disease, posi...   \n",
       "33851                                                NaN   \n",
       "32210  Because of in vitro studies, hydroxychloroquin...   \n",
       "22958                                                NaN   \n",
       "20225                                                NaN   \n",
       "\n",
       "                                          pdf_json_files  \\\n",
       "6498   document_parses/pdf_json/cd0e34984d3ba62e544e3...   \n",
       "33851                                                NaN   \n",
       "32210                                                NaN   \n",
       "22958                                                NaN   \n",
       "20225                                                NaN   \n",
       "\n",
       "                                     pmc_json_files  \n",
       "6498   document_parses/pmc_json/PMC7101537.xml.json  \n",
       "33851                                           NaN  \n",
       "32210                                           NaN  \n",
       "22958                                           NaN  \n",
       "20225  document_parses/pmc_json/PMC7150102.xml.json  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df = dd.read_csv(METADATA_FILE, dtype=str)\n",
    "metadata_df = metadata_df[[\"cord_uid\", \"title\", \"abstract\", \n",
    "                           \"pdf_json_files\", \"pmc_json_files\"]]\n",
    "\n",
    "# :TODO: comment for real run\n",
    "metadata_df = metadata_df.sample(frac=0.0005)\n",
    "\n",
    "metadata_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/saturn/lib/python3.7/site-packages/distributed/node.py:155: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 34997 instead\n",
      "  http_address[\"port\"], self.http_server.port\n"
     ]
    }
   ],
   "source": [
    "client = Client(processes=False, n_workers=2, threads_per_worker=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# :TODO: revisit for full dataset\n",
    "metadata_df = metadata_df.repartition(npartitions=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each record, we read the referenced file from the S3 filesystem, parse it into a JSON dictionary, and extract the text blocks we are interested in, namely the title, abstract (multiple paragraphs) and body (multiple paragraphs). We also compute the sequence number for each paragraph. This array of tuples (`pid`, `ptext`) is returned by the `parse_paragraphs` function below.\n",
    "\n",
    "We then explode the `paragraphs` column, and separate out the `pid` and `ptext` columns, then write them out into a set of Parquet files for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fully(filepath, s3, bucket_name):\n",
    "    obj = s3.Object(bucket_name, filepath)\n",
    "    s = obj.get()['Body'].read().decode('utf-8')\n",
    "    return s\n",
    "\n",
    "\n",
    "def parse_paragraphs(rows, bucket_name):\n",
    "    worker = get_worker()\n",
    "    try:\n",
    "        s3 = worker.s3\n",
    "    except:\n",
    "        s3 = boto3.resource('s3')\n",
    "        worker.s3 = s3\n",
    "    paragraphs = []\n",
    "    filepath = None\n",
    "    try:\n",
    "        if pd.notnull(rows.pdf_json_files):\n",
    "            filepath = rows.pdf_json_files\n",
    "        elif pd.notnull(rows.pmc_json_files):\n",
    "            filepath = rows.pmc_json_files\n",
    "        else:\n",
    "            pass\n",
    "        if filepath is not None:\n",
    "            abs_filepath = filepath.replace(\"document_parses\", \"cord19\")\n",
    "            fdict = json.loads(read_fully(abs_filepath, s3, bucket_name))\n",
    "            paragraphs.append((\"T\", fdict[\"metadata\"][\"title\"]))\n",
    "            paragraphs.extend([(\"A{:d}\".format(i), x[\"text\"]) \n",
    "                for i, x in enumerate(fdict[\"abstract\"])])\n",
    "            paragraphs.extend([(\"B{:d}\".format(i), x[\"text\"]) \n",
    "                for i, x in enumerate(fdict[\"body_text\"])])\n",
    "        else:\n",
    "            paragraphs.append((\"T\", rows[\"title\"]))\n",
    "            for i, abs_para_text in enumerate(rows[\"abstract\"].split('\\n')):\n",
    "                paragraphs.append((\"A{:d}\".format(i), abs_para_text))\n",
    "    except:\n",
    "        pass\n",
    "    return paragraphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_df = metadata_df.copy()\n",
    "paragraph_df[\"paragraphs\"] = paragraph_df.apply(\n",
    "    lambda rows: parse_paragraphs(rows, BUCKET_NAME), meta=(\"object\"), axis=1)\n",
    "paragraph_df = paragraph_df.drop(columns=[\"title\", \"abstract\",\n",
    "                                          \"pdf_json_files\", \"pmc_json_files\"])\n",
    "paragraph_df = paragraph_df.explode(\"paragraphs\")\n",
    "paragraph_df = paragraph_df.dropna()\n",
    "paragraph_df[\"pid\"] = paragraph_df.apply(lambda rows: rows.paragraphs[0], \n",
    "                                         meta=(\"str\"), axis=1)\n",
    "paragraph_df[\"ptext\"] = paragraph_df.apply(lambda rows: rows.paragraphs[1], \n",
    "                                           meta=(\"str\"), axis=1)\n",
    "paragraph_df = paragraph_df.drop(columns=[\"paragraphs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "\n",
    "fs = s3fs.S3FileSystem()\n",
    "if fs.exists(PARAGRAPH_FOLDER):\n",
    "    fs.rm(PARAGRAPH_FOLDER, recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://saturn-elsevierinc/cord19-paras-pq-sm'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PARAGRAPH_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.84 s, sys: 2.38 s, total: 8.22 s\n",
      "Wall time: 9.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "paragraph_df.to_parquet(PARAGRAPH_FOLDER, engine=\"pyarrow\", compression=\"snappy\")\n",
    "\n",
    "# paragraph_df.persist()\n",
    "# progress(paragraph_df)\n",
    "# results = paragraph_df.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>pid</th>\n",
       "      <th>ptext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6498</th>\n",
       "      <td>sz7qmi8q</td>\n",
       "      <td>T</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6498</th>\n",
       "      <td>sz7qmi8q</td>\n",
       "      <td>A0</td>\n",
       "      <td>Schwer punkt: Lun gen-und Pleura pa tho lo gie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6498</th>\n",
       "      <td>sz7qmi8q</td>\n",
       "      <td>A1</td>\n",
       "      <td>In traal veolä re Ak ku mu la ti on von SP-A I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6498</th>\n",
       "      <td>sz7qmi8q</td>\n",
       "      <td>A2</td>\n",
       "      <td>In traal veolä re Ak ku mu la ti on von pro SP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6498</th>\n",
       "      <td>sz7qmi8q</td>\n",
       "      <td>B0</td>\n",
       "      <td>Die hi sto pa tho lo gi sche Un ter su chung v...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cord_uid pid                                              ptext\n",
       "6498  sz7qmi8q   T                                                   \n",
       "6498  sz7qmi8q  A0  Schwer punkt: Lun gen-und Pleura pa tho lo gie...\n",
       "6498  sz7qmi8q  A1  In traal veolä re Ak ku mu la ti on von SP-A I...\n",
       "6498  sz7qmi8q  A2  In traal veolä re Ak ku mu la ti on von pro SP...\n",
       "6498  sz7qmi8q  B0  Die hi sto pa tho lo gi sche Un ter su chung v..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph_df = dd.read_parquet(PARAGRAPH_FOLDER, engine=\"pyarrow\")\n",
    "paragraph_df.head(npartitions=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1215"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paragraph_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
