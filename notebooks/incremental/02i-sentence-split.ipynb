{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Paragraphs to Sentences\n",
    "\n",
    "Input to this notebook is the output of the `01-load-and-parse.ipynb` notebook. We use the sentence splitter in the SciSpacy English Medium language model to split the paragraphs retrieved from the JSON files to sentences. At the end of this exercise, we should have a dataframe that contains the (`cord_uid`, `pid`, `sid`, `stext`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Dask Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-10-02 15:20:23] INFO - dask-saturn | Starting cluster. Status: pending\n",
      "[2020-10-02 15:20:28] INFO - dask-saturn | Starting cluster. Status: pending\n",
      "[2020-10-02 15:20:47] INFO - dask-saturn | Starting cluster. Status: pending\n",
      "[2020-10-02 15:21:24] INFO - dask-saturn | Starting cluster. Status: pending\n",
      "[2020-10-02 15:22:01] INFO - dask-saturn | Starting cluster. Status: pending\n",
      "[2020-10-02 15:22:44] INFO - dask-saturn | Starting cluster. Status: pending\n",
      "[2020-10-02 15:23:16] INFO - dask-saturn | Starting cluster. Status: pending\n",
      "[2020-10-02 15:24:11] INFO - dask-saturn | Starting cluster. Status: pending\n",
      "[2020-10-02 15:24:52] INFO - dask-saturn | Cluster is ready\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46b62bf89eb04d3a8d9fa9a2f378a402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>SaturnCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n  <style scoped>\\n   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dask.distributed import Client, wait\n",
    "from dask_saturn import SaturnCluster\n",
    "import time\n",
    "\n",
    "n_workers = 10\n",
    "cluster = SaturnCluster(n_workers=n_workers, scheduler_size='2xlarge', worker_size='4xlarge', nthreads=16)\n",
    "client = Client(cluster)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for workers, got 0\n",
      "Waiting for workers, got 0\n",
      "Waiting for workers, got 0\n",
      "Waiting for workers, got 0\n",
      "Waiting for workers, got 0\n",
      "Waiting for workers, got 0\n",
      "Waiting for workers, got 0\n",
      "Waiting for workers, got 0\n",
      "Waiting for workers, got 0\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "while len(client.scheduler_info()['workers']) < n_workers:\n",
    "    print('Waiting for workers, got', len(client.scheduler_info()['workers']))\n",
    "    time.sleep(30)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import s3fs\n",
    "import scispacy\n",
    "\n",
    "from dask.distributed import Client, progress, get_worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"saturn-elsevierinc\"\n",
    "\n",
    "PARAGRAPH_FOLDER = \"/\".join([\"s3:/\", BUCKET_NAME, \"incremental\", \"added\"])\n",
    "SENTENCE_FOLDER = \"/\".join([\"s3:/\", BUCKET_NAME, \"incremental\", \"add-sents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>pid</th>\n",
       "      <th>ptext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38548</th>\n",
       "      <td>l2m8y422</td>\n",
       "      <td>T</td>\n",
       "      <td>Correction: Selective laser trabeculoplasty: p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38563</th>\n",
       "      <td>kwby80nj</td>\n",
       "      <td>T</td>\n",
       "      <td>Publishing in the transfusion field: “Like a B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38565</th>\n",
       "      <td>9vbwzi8v</td>\n",
       "      <td>T</td>\n",
       "      <td>Nachfrage nicht zu bremsen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38568</th>\n",
       "      <td>w6bnygac</td>\n",
       "      <td>T</td>\n",
       "      <td>Editor’s Focus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38572</th>\n",
       "      <td>k4bcmeke</td>\n",
       "      <td>T</td>\n",
       "      <td>Introduction to the September 2020 Special Iss...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cord_uid pid                                              ptext\n",
       "38548  l2m8y422   T  Correction: Selective laser trabeculoplasty: p...\n",
       "38563  kwby80nj   T  Publishing in the transfusion field: “Like a B...\n",
       "38565  9vbwzi8v   T                         Nachfrage nicht zu bremsen\n",
       "38568  w6bnygac   T                                     Editor’s Focus\n",
       "38572  k4bcmeke   T  Introduction to the September 2020 Special Iss..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph_df = dd.read_parquet(PARAGRAPH_FOLDER, engine=\"pyarrow\")\n",
    "paragraph_df = paragraph_df.dropna()\n",
    "paragraph_df.head(npartitions=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58621"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paragraph_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_large_text(large_text, chunk_size, max_batch_size):\n",
    "    text_len = len(large_text)\n",
    "    start, end, texts = 0, 0, []\n",
    "    while start < text_len or len(texts) >= max_batch_size:\n",
    "        try:\n",
    "            end = start + text[start : start + chunk_size].rindex('.')\n",
    "            texts.append(text[start : end + 1])\n",
    "            if end == start:\n",
    "                break\n",
    "            start = end + 1\n",
    "        except:\n",
    "            break\n",
    "    if start < text_len and len(texts) < max_batch_size:\n",
    "        texts.append(text[start:])\n",
    "    return texts\n",
    "            \n",
    "\n",
    "def handle_row(row, nlp, max_text_length=1000000, max_batch_size=10):\n",
    "    # max_text_length is a SpaCy limit\n",
    "    ptext = row.ptext\n",
    "    if len(ptext) > max_text_length:\n",
    "        texts = chunk_large_text(\n",
    "            ptext, max_text_length * 0.9, max_batch_size)\n",
    "    else:\n",
    "        texts = [ptext]\n",
    "    sents = []\n",
    "    for doc in nlp.pipe(texts, n_threads=16, batch_size=len(texts)):\n",
    "        for sid, sent in enumerate(doc.sents):\n",
    "            sents.append((sid, sent.text))\n",
    "    return sents\n",
    "\n",
    "\n",
    "def handle_partition(part):\n",
    "    worker = get_worker()\n",
    "    try:\n",
    "        nlp = worker.nlp\n",
    "    except:\n",
    "        nlp = spacy.load(\"en_core_sci_md\", disable=[\"tagger\", \"ner\"])\n",
    "        worker.nlp = nlp\n",
    "    sentences = part.apply(lambda rows: handle_row(rows, nlp), \n",
    "                           axis=1)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_df = paragraph_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_df[\"sentences\"] = sentence_df.map_partitions(\n",
    "    lambda part: handle_partition(part), meta=(\"object\"))\n",
    "sentence_df = sentence_df.drop(columns=[\"ptext\"])\n",
    "sentence_df = sentence_df.explode(\"sentences\")\n",
    "sentence_df = sentence_df.dropna()\n",
    "sentence_df[\"sid\"] = sentence_df.apply(\n",
    "    lambda row: row.sentences[0], meta=(\"int\"), axis=1)\n",
    "sentence_df[\"stext\"] = sentence_df.apply(\n",
    "    lambda row: row.sentences[1], meta=(\"str\"), axis=1)\n",
    "sentence_df = sentence_df.drop(columns=[\"sentences\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_df.cord_uid = sentence_df.cord_uid.astype(str)\n",
    "sentence_df.pid = sentence_df.pid.astype(str)\n",
    "sentence_df.sid = sentence_df.sid.astype(np.int32)\n",
    "sentence_df.stext = sentence_df.stext.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = s3fs.S3FileSystem()\n",
    "if fs.exists(SENTENCE_FOLDER):\n",
    "    fs.rm(SENTENCE_FOLDER, recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence partitions are not evenly sized which can cause problems\n",
    "# with downstream tasks, so repartitioning for performance.\n",
    "# check with:\n",
    "# part_len = sentences.map_partitions(len).compute()\n",
    "# part_len.describe()\n",
    "sentence_df = sentence_df.repartition(partition_size=\"20MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 700 ms, sys: 21.2 ms, total: 721 ms\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentence_df.to_parquet(SENTENCE_FOLDER, engine=\"pyarrow\", compression=\"snappy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://saturn-elsevierinc/incremental/add-sents'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SENTENCE_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.028721"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs.du(SENTENCE_FOLDER) / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>pid</th>\n",
       "      <th>sid</th>\n",
       "      <th>stext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38548</th>\n",
       "      <td>l2m8y422</td>\n",
       "      <td>T</td>\n",
       "      <td>0</td>\n",
       "      <td>Correction: Selective laser trabeculoplasty: p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38563</th>\n",
       "      <td>kwby80nj</td>\n",
       "      <td>T</td>\n",
       "      <td>0</td>\n",
       "      <td>Publishing in the transfusion field: “</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38563</th>\n",
       "      <td>kwby80nj</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>Like a Bridge Over Trouble Water” in a “The time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38563</th>\n",
       "      <td>kwby80nj</td>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>They Are A Changing” period</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38565</th>\n",
       "      <td>9vbwzi8v</td>\n",
       "      <td>T</td>\n",
       "      <td>0</td>\n",
       "      <td>Nachfrage nicht zu bremsen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cord_uid pid  sid                                              stext\n",
       "38548  l2m8y422   T    0  Correction: Selective laser trabeculoplasty: p...\n",
       "38563  kwby80nj   T    0             Publishing in the transfusion field: “\n",
       "38563  kwby80nj   T    1   Like a Bridge Over Trouble Water” in a “The time\n",
       "38563  kwby80nj   T    2                        They Are A Changing” period\n",
       "38565  9vbwzi8v   T    0                         Nachfrage nicht zu bremsen"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_df = dd.read_parquet(SENTENCE_FOLDER, engine=\"pyarrow\")\n",
    "sentence_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "228953"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do this if youre done using the cluster\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
