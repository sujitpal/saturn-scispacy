{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity Extraction from old-style SciSpacy NER Models\n",
    "\n",
    "These models identify the entity span in an input sentence, but don't attempt to separately link to an external taxonomy. The following variations are possible here. Replace the `MODEL_NAME, MODEL_ALIAS` line in the cell below and repeat run to extract named entity information from the chosen model.\n",
    "\n",
    "We can run this notebook with different values of `MODEL_NAME` and `MODEL_ALIAS` to create different entity dumps from each model.\n",
    "\n",
    "## Initialize Dask Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'medium': 'Medium - 2 cores - 4 GB RAM',\n",
       " 'large': 'Large - 2 cores - 16 GB RAM',\n",
       " 'xlarge': 'XLarge - 4 cores - 32 GB RAM',\n",
       " '2xlarge': '2XLarge - 8 cores - 64 GB RAM',\n",
       " '4xlarge': '4XLarge - 16 cores - 128 GB RAM',\n",
       " '8xlarge': '8XLarge - 32 cores - 256 GB RAM',\n",
       " '12xlarge': '12XLarge - 48 cores - 384 GB RAM',\n",
       " '16xlarge': '16XLarge - 64 cores - 512 GB RAM',\n",
       " 'g4dnxlarge': 'T4-XLarge - 4 cores - 16 GB RAM - 1 GPU',\n",
       " 'g4dn4xlarge': 'T4-4XLarge - 16 cores - 64 GB RAM - 1 GPU',\n",
       " 'g4dn8xlarge': 'T4-8XLarge - 32 cores - 128 GB RAM - 1 GPU',\n",
       " 'p32xlarge': 'V100-2XLarge - 8 cores - 61 GB RAM - 1 GPU',\n",
       " 'p38xlarge': 'V100-8XLarge - 32 cores - 244 GB RAM - 4 GPU',\n",
       " 'p316xlarge': 'V100-16XLarge - 64 cores - 488 GB RAM - 8 GPU'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask_saturn.core import describe_sizes\n",
    "\n",
    "describe_sizes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-10-02 15:37:24] INFO - dask-saturn | Starting cluster. Status: pending\n",
      "[2020-10-02 15:37:31] INFO - dask-saturn | Starting cluster. Status: pending\n",
      "[2020-10-02 15:37:45] INFO - dask-saturn | Starting cluster. Status: pending\n",
      "[2020-10-02 15:38:11] INFO - dask-saturn | Cluster is ready\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f79325206b54e87b873d06f09737595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>SaturnCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n  <style scoped>\\n   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dask.distributed import Client, wait\n",
    "from dask_saturn import SaturnCluster\n",
    "import time\n",
    "\n",
    "n_workers = 5\n",
    "cluster = SaturnCluster(n_workers=n_workers, \n",
    "                        scheduler_size='2xlarge', \n",
    "                        worker_size='4xlarge', \n",
    "                        nthreads=16)\n",
    "client = Client(cluster)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for workers, got 0\n",
      "Waiting for workers, got 3\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "while len(client.scheduler_info()['workers']) < n_workers:\n",
    "    print('Waiting for workers, got', len(client.scheduler_info()['workers']))\n",
    "    time.sleep(30)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "import spacy\n",
    "import scispacy\n",
    "\n",
    "from dask.distributed import Client, progress, get_worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME, MODEL_ALIAS = \"en_ner_craft_md\", \"craft\"\n",
    "# MODEL_NAME, MODEL_ALIAS = \"en_ner_jnlpba_md\", \"jnlpba\"\n",
    "# MODEL_NAME, MODEL_ALIAS = \"en_ner_bc5cdr_md\", \"bc5cdr\"\n",
    "# MODEL_NAME, MODEL_ALIAS = \"en_ner_bionlp13cg_md\", \"bionlp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"saturn-elsevierinc\"\n",
    "\n",
    "SENTENCE_FOLDER = \"/\".join([\"s3:/\", BUCKET_NAME, \"incremental\", \"add-sents\"])\n",
    "ENTITIES_FOLDER = \"/\".join([\"s3:/\", BUCKET_NAME, \"incremental\",\n",
    "                            \"add-ents-{:s}\".format(MODEL_ALIAS)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>pid</th>\n",
       "      <th>sid</th>\n",
       "      <th>stext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38548</th>\n",
       "      <td>l2m8y422</td>\n",
       "      <td>T</td>\n",
       "      <td>0</td>\n",
       "      <td>Correction: Selective laser trabeculoplasty: p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38563</th>\n",
       "      <td>kwby80nj</td>\n",
       "      <td>T</td>\n",
       "      <td>0</td>\n",
       "      <td>Publishing in the transfusion field: “</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38563</th>\n",
       "      <td>kwby80nj</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>Like a Bridge Over Trouble Water” in a “The time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38563</th>\n",
       "      <td>kwby80nj</td>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>They Are A Changing” period</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38565</th>\n",
       "      <td>9vbwzi8v</td>\n",
       "      <td>T</td>\n",
       "      <td>0</td>\n",
       "      <td>Nachfrage nicht zu bremsen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cord_uid pid  sid                                              stext\n",
       "38548  l2m8y422   T    0  Correction: Selective laser trabeculoplasty: p...\n",
       "38563  kwby80nj   T    0             Publishing in the transfusion field: “\n",
       "38563  kwby80nj   T    1   Like a Bridge Over Trouble Water” in a “The time\n",
       "38563  kwby80nj   T    2                        They Are A Changing” period\n",
       "38565  9vbwzi8v   T    0                         Nachfrage nicht zu bremsen"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_df = dd.read_parquet(SENTENCE_FOLDER, engine=\"pyarrow\")\n",
    "sentences_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "228953"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_batch(sents, nlp, ent_class):\n",
    "    docs = nlp.pipe(sents, n_threads=16, batch_size=len(sents))\n",
    "    ents_list = []\n",
    "    for doc in docs:\n",
    "        ents = []\n",
    "        for eid, ent in enumerate(doc.ents):\n",
    "            ents.append((eid, ent_class, ent.text, ent.label_, \n",
    "                         1.0, ent.start_char, ent.end_char))\n",
    "        ents_list.append(ents)\n",
    "    return ents_list\n",
    "\n",
    "\n",
    "def handle_partition(part):\n",
    "    worker = get_worker()\n",
    "    try:\n",
    "        nlp = worker.nlp\n",
    "    except:\n",
    "        nlp = spacy.load(MODEL_NAME)\n",
    "        worker.nlp = nlp\n",
    "    batch_size = 32\n",
    "    sent_batch, ent_batch, entities = [], [], []\n",
    "    for _, row in part.iterrows():\n",
    "        if len(sent_batch) % batch_size == 0 and len(sent_batch) > 0:\n",
    "            ent_batch = handle_batch(sent_batch, nlp, MODEL_ALIAS)\n",
    "            entities.extend(ent_batch)\n",
    "            sent_batch = []\n",
    "        try:\n",
    "            sent_batch.append(row.stext)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    if len(sent_batch) > 0:\n",
    "        ent_batch = handle_batch(sent_batch, nlp, MODEL_ALIAS)\n",
    "        entities.extend(ent_batch)\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_df = sentences_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_df[\"entities\"] = entities_df.map_partitions(\n",
    "    lambda part: handle_partition(part), meta=(\"object\"))\n",
    "entities_df = entities_df.drop(columns=[\"stext\"])\n",
    "entities_df = entities_df.explode(\"entities\")\n",
    "entities_df = entities_df.dropna()\n",
    "\n",
    "entities_df[\"eid\"] = entities_df.apply(\n",
    "    lambda row: row.entities[0], meta=(\"int\"), axis=1)\n",
    "entities_df[\"eclass\"] = entities_df.apply(\n",
    "    lambda row: row.entities[1], meta=(\"str\"), axis=1)\n",
    "entities_df[\"etext\"] = entities_df.apply(\n",
    "    lambda row: row.entities[2], meta=(\"str\"), axis=1)\n",
    "entities_df[\"elabel\"] = entities_df.apply(\n",
    "    lambda row: row.entities[3], meta=(\"str\"), axis=1)\n",
    "entities_df[\"escore\"] = entities_df.apply(\n",
    "    lambda row: row.entities[4], meta=(\"float\"), axis=1)\n",
    "entities_df[\"ent_start_char\"] = entities_df.apply(\n",
    "    lambda row: row.entities[5], meta=(\"int\"), axis=1)\n",
    "entities_df[\"ent_end_char\"] = entities_df.apply(\n",
    "    lambda row: row.entities[6], meta=(\"int\"), axis=1)\n",
    "\n",
    "entities_df = entities_df.drop(columns=[\"entities\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_df.cord_uid = entities_df.cord_uid.astype(str)\n",
    "entities_df.pid = entities_df.pid.astype(str)\n",
    "entities_df.sid = entities_df.sid.astype(np.int32)\n",
    "entities_df.eid = entities_df.eid.astype(np.int32)\n",
    "entities_df.eclass = entities_df.eclass.astype(str)\n",
    "entities_df.etext = entities_df.etext.astype(str)\n",
    "entities_df.elabel = entities_df.elabel.astype(str)\n",
    "entities_df.escore = entities_df.escore.astype(np.float32)\n",
    "entities_df.ent_start_char = entities_df.ent_start_char.astype(np.int32)\n",
    "entities_df.ent_end_char = entities_df.ent_end_char.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = s3fs.S3FileSystem()\n",
    "if fs.exists(ENTITIES_FOLDER):\n",
    "    fs.rm(ENTITIES_FOLDER, recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 169 ms, sys: 42 ms, total: 211 ms\n",
      "Wall time: 3min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "entities_df.to_parquet(ENTITIES_FOLDER, engine=\"pyarrow\", compression=\"snappy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://saturn-elsevierinc/incremental/add-ents-craft'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ENTITIES_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.811986"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs.du(ENTITIES_FOLDER) / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>pid</th>\n",
       "      <th>sid</th>\n",
       "      <th>eid</th>\n",
       "      <th>eclass</th>\n",
       "      <th>etext</th>\n",
       "      <th>elabel</th>\n",
       "      <th>escore</th>\n",
       "      <th>ent_start_char</th>\n",
       "      <th>ent_end_char</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38563</th>\n",
       "      <td>kwby80nj</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>craft</td>\n",
       "      <td>Water</td>\n",
       "      <td>CHEBI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38584</th>\n",
       "      <td>7y9ewt2v</td>\n",
       "      <td>T</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>craft</td>\n",
       "      <td>viruses</td>\n",
       "      <td>TAXON</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38622</th>\n",
       "      <td>3qupx9yp</td>\n",
       "      <td>T</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>craft</td>\n",
       "      <td>Stem Cell</td>\n",
       "      <td>CL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38622</th>\n",
       "      <td>3qupx9yp</td>\n",
       "      <td>T</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>craft</td>\n",
       "      <td>Vesicles/Exosomes</td>\n",
       "      <td>GGP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>158</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38726</th>\n",
       "      <td>oqf6kopn</td>\n",
       "      <td>A0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>craft</td>\n",
       "      <td>mukosalen</td>\n",
       "      <td>TAXON</td>\n",
       "      <td>1.0</td>\n",
       "      <td>185</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cord_uid pid  sid  eid eclass              etext elabel  escore  \\\n",
       "38563  kwby80nj   T    1    0  craft              Water  CHEBI     1.0   \n",
       "38584  7y9ewt2v   T    0    0  craft            viruses  TAXON     1.0   \n",
       "38622  3qupx9yp   T    0    0  craft          Stem Cell     CL     1.0   \n",
       "38622  3qupx9yp   T    0    1  craft  Vesicles/Exosomes    GGP     1.0   \n",
       "38726  oqf6kopn  A0    2    0  craft          mukosalen  TAXON     1.0   \n",
       "\n",
       "       ent_start_char  ent_end_char  \n",
       "38563              27            32  \n",
       "38584              21            28  \n",
       "38622              11            20  \n",
       "38622             158           175  \n",
       "38726             185           194  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities_df = dd.read_parquet(ENTITIES_FOLDER, engine=\"pyarrow\")\n",
    "entities_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156962"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entities_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.client - ERROR - Failed to reconnect to scheduler after 10.00 seconds, closing client\n",
      "_GatheringFuture exception was never retrieved\n",
      "future: <_GatheringFuture finished exception=CancelledError()>\n",
      "concurrent.futures._base.CancelledError\n"
     ]
    }
   ],
   "source": [
    "# do this if youre done using the cluster\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
