{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incremental Post-processor\n",
    "\n",
    "This notebook uses the `incremental/added` and `incremental/deleted` data generated by `05ax-incremental-pre` and applies it to each of the outputs of the full pipeline.\n",
    "\n",
    "* Run the entire pipeline on the paragraphs from the `incremental/added` file. This is the `incremental/[entity_name]` file.\n",
    "* Read the `[entity_name]` file from previous run.\n",
    "* Apply the deletions from the `incremental/deleted` files to `[output_entity_name]` file.\n",
    "* Concatenate the additions from `incremental/[entity_name]` files.\n",
    "* Repartition and write output file `[output_entity_name]`.\n",
    "\n",
    "## Initialize Dask Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_saturn.core import describe_sizes\n",
    "\n",
    "describe_sizes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, wait\n",
    "from dask_saturn import SaturnCluster\n",
    "import time\n",
    "\n",
    "n_workers = 10\n",
    "cluster = SaturnCluster(n_workers=n_workers, scheduler_size='2xlarge', worker_size='4xlarge', nthreads=16)\n",
    "client = Client(cluster)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while len(client.scheduler_info()['workers']) < n_workers:\n",
    "    print('Waiting for workers, got', len(client.scheduler_info()['workers']))\n",
    "    time.sleep(30)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import dask.dataframe as dd\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "\n",
    "from dask.distributed import Client, progress, get_worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"s3://saturn-elsevierinc\"\n",
    "\n",
    "D1 = \"2020-08-28\"\n",
    "D2 = \"2020-09-28\"\n",
    "\n",
    "DIFF_ADD_FOLDER = \"/\".join([BUCKET_NAME, \"incremental\", \"added\"])\n",
    "DIFF_DEL_FOLDER = \"/\".join([BUCKET_NAME, \"incremental\", \"deleted\"])\n",
    "\n",
    "PARA_FULL_FOLDER = \"/\".join([BUCKET_NAME, \"cord19-paras-pq\"])\n",
    "PARA_INC_FOLDER = \"/\".join([BUCKET_NAME, \"incremental\", \"added\"])\n",
    "PARA_MERGED_FOLDER = \"/\".join([BUCKET_NAME, D2, \"cord19-paras-pq\"])\n",
    "\n",
    "SENT_FULL_FOLDER = \"/\".join([BUCKET_NAME, \"cord19-sents-pqr\"])\n",
    "SENT_INC_FOLDER = \"/\".join([BUCKET_NAME, \"incremental\", \"add-sents\"])\n",
    "SENT_MERGED_FOLDER = \"/\".join([BUCKET_NAME, D2, \"cord19-sents-pq\"])\n",
    "\n",
    "MODEL_NAMES = [\n",
    "    \"craft\", \"jnlpba\", \"bc5cdr\", \"bionlp\",\n",
    "    \"umls\", \"mesh\", \"go\", \"hpo\", \"rxnorm\"\n",
    "]\n",
    "ENT_FULL_FOLDER_T = \"/\".join([BUCKET_NAME, \"cord19-ents-{:s}-pq\")])\n",
    "ENT_INC_FOLDER_T = \"/\".join([BUCKET_NAME, \"incremental\", \"add-ents-{:s}\"])\n",
    "ENT_MERGED_FOLDER_T = \"/\".join([BUCKET_NAME, D2, \"cord19-ents-{:s}-pq\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = s3fs.S3FileSystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_df = dd.read_parquet(DIFF_DEL_FOLDER, engine=\"pyarrow\")\n",
    "add_df = dd.read_parquet(DIFF_ADD_FOLDER, engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Input: {:s}\".format(PARA_FULL_FOLDER))\n",
    "print(\"Incremental: {:s}\".format(PARA_INC_FOLDER))\n",
    "print(\"Merged: {:s}\".format(PARA_MERGED_FOLDER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_full_df = dd.read_parquet(PARA_FULL_FOLDER, engine=\"pyarrow\")\n",
    "para_inc_df = dd.read_parquet(PARA_INC_FOLDER, engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_diff_rows(full_df, del_df):\n",
    "    # remove rows listed in del_df from para_full_df\n",
    "    result_df = full_df.merge(del_df, how=\"outer\", indicator=True,\n",
    "                              on=[\"cord_uid\"], suffixes=[\"_d1\", \"_d2\"])\n",
    "    result_df = result_df[result_df._merge == \"left_only\"]\n",
    "\n",
    "    # drop extra cols acquired from del_df, rename para_full_df cols\n",
    "    drop_cols = [x for x in result_df.columns if x.endswith(\"_d2\")]\n",
    "    rename_cols = {x : x[0:-3] for x in result_df.columns if x.endswith(\"_d1\")}\n",
    "    result_df = result_df.drop(columns=drop_cols)\n",
    "    result_df = result_df.rename(columns=rename_cols)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "\n",
    "def add_diff_rows(full_df, inc_df):\n",
    "    result_df = dd.concat([full_df, inc_df], axis=0, interleave_partitions=True)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_df = delete_diff_rows(para_full_df, del_df)\n",
    "para_df = add_diff_rows(para_df, para_inc_df)\n",
    "\n",
    "para_df.cord_uid = para_df.cord_uid.astype(str)\n",
    "para_df.pid = para_df.pid.astype(str)\n",
    "para_df.ptext = para_df.ptext.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fs.exists(PARA_MERGED_FOLDER):\n",
    "    fs.rm(PARA_MERGED_FOLDER, recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "para_df.to_parquet(PARA_MERGED_FOLDER, engine=\"pyarrow\", compression=\"snappy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.du(PARA_MERGED_FOLDER) / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_df = dd.read_parquet(PARA_MERGED_FOLDER, engine=\"pyarrow\")\n",
    "para_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(para_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Input: {:s}\".format(SENT_FULL_FOLDER))\n",
    "print(\"Incremental: {:s}\".format(SENT_INC_FOLDER))\n",
    "print(\"Merged: {:s}\".format(SENT_MERGED_FOLDER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_full_df = dd.read_parquet(SENT_FULL_FOLDER, engine=\"pyarrow\")\n",
    "sent_inc_df = dd.read_parquet(SENT_INC_FOLDER, engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_df = delete_diff_rows(sent_full_df, del_df)\n",
    "sent_df = add_diff_rows(sent_df, sent_inc_df)\n",
    "\n",
    "sent_df.cord_uid = sent_df.cord_uid.astype(str)\n",
    "sent_df.pid = sent_df.pid.astype(str)\n",
    "sent_df.sid = sent_df.sid.astype(np.int32)\n",
    "sent_df.stext = sent_df.stext.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fs.exists(SENT_MERGED_FOLDER):\n",
    "    fs.rm(SENT_MERGED_FOLDER, recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sent_df.to_parquet(SENT_MERGED_FOLDER, engine=\"pyarrow\", compression=\"snappy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.du(SENT_MERGED_FOLDER) / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_df = dd.read_parquet(SENT_MERGED_FOLDER, engine=\"pyarrow\")\n",
    "sent_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sent_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entities(0): CRAFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_entity_dtypes(entities_df):\n",
    "    entities_df.cord_uid = entities_df.cord_uid.astype(str)\n",
    "    entities_df.pid = entities_df.pid.astype(str)\n",
    "    entities_df.sid = entities_df.sid.astype(np.int32)\n",
    "    entities_df.eid = entities_df.eid.astype(np.int32)\n",
    "    entities_df.eclass = entities_df.eclass.astype(str)\n",
    "    entities_df.etext = entities_df.etext.astype(str)\n",
    "    entities_df.elabel = entities_df.elabel.astype(str)\n",
    "    entities_df.escore = entities_df.escore.astype(np.float32)\n",
    "    entities_df.ent_start_char = entities_df.ent_start_char.astype(np.int32)\n",
    "    entities_df.ent_end_char = entities_df.ent_end_char.astype(np.int32)\n",
    "    return entities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "ent_full_folder = ENT_FULL_FOLDER_T.format(MODEL_NAMES[i])\n",
    "ent_inc_folder = ENT_INC_FOLDER_T.format(MODEL_NAMES[i])\n",
    "ent_merged_folder = ENT_MERGED_FOLDER_T.format(MODEL_NAMES[i])\n",
    "\n",
    "print(\"Input: {:s}\".format(ent_full_folder))\n",
    "print(\"Incremental: {:s}\".format(ent_inc_folder))\n",
    "print(\"Merged: {:s}\".format(ent_merged_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_full_df = dd.read_parquet(ent_full_folder, engine=\"pyarrow\")\n",
    "ent_inc_df = dd.read_parquet(ent_inc_folder, engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_df = delete_diff_rows(ent_full_df, del_df)\n",
    "ent_df = add_diff_rows(ent_df, ent_inc_df)\n",
    "ent_df = set_entity_dtypes(ent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fs.exists(ent_merged_folder):\n",
    "    fs.rm(ent_merged_folder, recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ent_df.to_parquet(ent_merged_folder, engine=\"pyarrow\", compression=\"snappy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.du(ent_merged_folder) / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_df = dd.read_parquet(ent_merged_folder, engine=\"pyarrow\")\n",
    "ent_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ent_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entities(1): JNLPBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "ent_full_folder = ENT_FULL_FOLDER_T.format(MODEL_NAMES[i])\n",
    "ent_inc_folder = ENT_INC_FOLDER_T.format(MODEL_NAMES[i])\n",
    "ent_merged_folder = ENT_MERGED_FOLDER_T.format(MODEL_NAMES[i])\n",
    "\n",
    "print(\"Input: {:s}\".format(ent_full_folder))\n",
    "print(\"Incremental: {:s}\".format(ent_inc_folder))\n",
    "print(\"Merged: {:s}\".format(ent_merged_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_full_df = dd.read_parquet(ent_full_folder, engine=\"pyarrow\")\n",
    "ent_inc_df = dd.read_parquet(ent_inc_folder, engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_df = delete_diff_rows(ent_full_df, del_df)\n",
    "ent_df = add_diff_rows(ent_df, ent_inc_df)\n",
    "ent_df = set_entity_dtypes(ent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fs.exists(ent_merged_folder):\n",
    "    fs.rm(ent_merged_folder, recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ent_df.to_parquet(ent_merged_folder, engine=\"pyarrow\", compression=\"snappy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.du(ent_merged_folder) / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_df = dd.read_parquet(ent_merged_folder, engine=\"pyarrow\")\n",
    "ent_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ent_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entities(2): BC5CDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "ent_full_folder = ENT_FULL_FOLDER_T.format(MODEL_NAMES[i])\n",
    "ent_inc_folder = ENT_INC_FOLDER_T.format(MODEL_NAMES[i])\n",
    "ent_merged_folder = ENT_MERGED_FOLDER_T.format(MODEL_NAMES[i])\n",
    "\n",
    "print(\"Input: {:s}\".format(ent_full_folder))\n",
    "print(\"Incremental: {:s}\".format(ent_inc_folder))\n",
    "print(\"Merged: {:s}\".format(ent_merged_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_full_df = dd.read_parquet(ent_full_folder, engine=\"pyarrow\")\n",
    "ent_inc_df = dd.read_parquet(ent_inc_folder, engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_df = delete_diff_rows(ent_full_df, del_df)\n",
    "ent_df = add_diff_rows(ent_df, ent_inc_df)\n",
    "ent_df = set_entity_dtypes(ent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fs.exists(ent_merged_folder):\n",
    "    fs.rm(ent_merged_folder, recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ent_df.to_parquet(ent_merged_folder, engine=\"pyarrow\", compression=\"snappy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.du(ent_merged_folder) / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_df = dd.read_parquet(ent_merged_folder, engine=\"pyarrow\")\n",
    "ent_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ent_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entities(3): BioNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "ent_full_folder = ENT_FULL_FOLDER_T.format(MODEL_NAMES[i])\n",
    "ent_inc_folder = ENT_INC_FOLDER_T.format(MODEL_NAMES[i])\n",
    "ent_merged_folder = ENT_MERGED_FOLDER_T.format(MODEL_NAMES[i])\n",
    "\n",
    "print(\"Input: {:s}\".format(ent_full_folder))\n",
    "print(\"Incremental: {:s}\".format(ent_inc_folder))\n",
    "print(\"Merged: {:s}\".format(ent_merged_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_full_df = dd.read_parquet(ent_full_folder, engine=\"pyarrow\")\n",
    "ent_inc_df = dd.read_parquet(ent_inc_folder, engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_df = delete_diff_rows(ent_full_df, del_df)\n",
    "ent_df = add_diff_rows(ent_df, ent_inc_df)\n",
    "ent_df = set_entity_dtypes(ent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fs.exists(ent_merged_folder):\n",
    "    fs.rm(ent_merged_folder, recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ent_df.to_parquet(ent_merged_folder, engine=\"pyarrow\", compression=\"snappy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.du(ent_merged_folder) / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_df = dd.read_parquet(ent_merged_folder, engine=\"pyarrow\")\n",
    "ent_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ent_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entities(4): UMLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 4\n",
    "ent_full_folder = ENT_FULL_FOLDER_T.format(MODEL_NAMES[i])\n",
    "ent_inc_folder = ENT_INC_FOLDER_T.format(MODEL_NAMES[i])\n",
    "ent_merged_folder = ENT_MERGED_FOLDER_T.format(MODEL_NAMES[i])\n",
    "\n",
    "print(\"Input: {:s}\".format(ent_full_folder))\n",
    "print(\"Incremental: {:s}\".format(ent_inc_folder))\n",
    "print(\"Merged: {:s}\".format(ent_merged_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_full_df = dd.read_parquet(ent_full_folder, engine=\"pyarrow\")\n",
    "ent_inc_df = dd.read_parquet(ent_inc_folder, engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_df = delete_diff_rows(ent_full_df, del_df)\n",
    "ent_df = add_diff_rows(ent_df, ent_inc_df)\n",
    "ent_df = set_entity_dtypes(ent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fs.exists(ent_merged_folder):\n",
    "    fs.rm(ent_merged_folder, recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ent_df.to_parquet(ent_merged_folder, engine=\"pyarrow\", compression=\"snappy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.du(ent_merged_folder) / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_df = dd.read_parquet(ent_merged_folder, engine=\"pyarrow\")\n",
    "ent_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ent_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entities(5): MeSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 5\n",
    "ent_full_folder = ENT_FULL_FOLDER_T.format(MODEL_NAMES[i])\n",
    "ent_inc_folder = ENT_INC_FOLDER_T.format(MODEL_NAMES[i])\n",
    "ent_merged_folder = ENT_MERGED_FOLDER_T.format(MODEL_NAMES[i])\n",
    "\n",
    "print(\"Input: {:s}\".format(ent_full_folder))\n",
    "print(\"Incremental: {:s}\".format(ent_inc_folder))\n",
    "print(\"Merged: {:s}\".format(ent_merged_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_full_df = dd.read_parquet(ent_full_folder, engine=\"pyarrow\")\n",
    "ent_inc_df = dd.read_parquet(ent_inc_folder, engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_df = delete_diff_rows(ent_full_df, del_df)\n",
    "ent_df = add_diff_rows(ent_df, ent_inc_df)\n",
    "ent_df = set_entity_dtypes(ent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fs.exists(ent_merged_folder):\n",
    "    fs.rm(ent_merged_folder, recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ent_df.to_parquet(ent_merged_folder, engine=\"pyarrow\", compression=\"snappy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.du(ent_merged_folder) / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_df = dd.read_parquet(ent_merged_folder, engine=\"pyarrow\")\n",
    "ent_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ent_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entities(6): GO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 6\n",
    "ent_full_folder = ENT_FULL_FOLDER_T.format(MODEL_NAMES[i])\n",
    "ent_inc_folder = ENT_INC_FOLDER_T.format(MODEL_NAMES[i])\n",
    "ent_merged_folder = ENT_MERGED_FOLDER_T.format(MODEL_NAMES[i])\n",
    "\n",
    "print(\"Input: {:s}\".format(ent_full_folder))\n",
    "print(\"Incremental: {:s}\".format(ent_inc_folder))\n",
    "print(\"Merged: {:s}\".format(ent_merged_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_full_df = dd.read_parquet(ent_full_folder, engine=\"pyarrow\")\n",
    "ent_inc_df = dd.read_parquet(ent_inc_folder, engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_df = delete_diff_rows(ent_full_df, del_df)\n",
    "ent_df = add_diff_rows(ent_df, ent_inc_df)\n",
    "ent_df = set_entity_dtypes(ent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fs.exists(ent_merged_folder):\n",
    "    fs.rm(ent_merged_folder, recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ent_df.to_parquet(ent_merged_folder, engine=\"pyarrow\", compression=\"snappy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.du(ent_merged_folder) / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_df = dd.read_parquet(ent_merged_folder, engine=\"pyarrow\")\n",
    "ent_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ent_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entities(7): HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ENT_FULL_FOLDER_T' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8f2db1178388>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ment_full_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mENT_FULL_FOLDER_T\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_NAMES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0ment_inc_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mENT_INC_FOLDER_T\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_NAMES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0ment_merged_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mENT_MERGED_FOLDER_T\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_NAMES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ENT_FULL_FOLDER_T' is not defined"
     ]
    }
   ],
   "source": [
    "i = 7\n",
    "ent_full_folder = ENT_FULL_FOLDER_T.format(MODEL_NAMES[i])\n",
    "ent_inc_folder = ENT_INC_FOLDER_T.format(MODEL_NAMES[i])\n",
    "ent_merged_folder = ENT_MERGED_FOLDER_T.format(MODEL_NAMES[i])\n",
    "\n",
    "print(\"Input: {:s}\".format(ent_full_folder))\n",
    "print(\"Incremental: {:s}\".format(ent_inc_folder))\n",
    "print(\"Merged: {:s}\".format(ent_merged_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_full_df = dd.read_parquet(ent_full_folder, engine=\"pyarrow\")\n",
    "ent_inc_df = dd.read_parquet(ent_inc_folder, engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_df = delete_diff_rows(ent_full_df, del_df)\n",
    "ent_df = add_diff_rows(ent_df, ent_inc_df)\n",
    "ent_df = set_entity_dtypes(ent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fs.exists(ent_merged_folder):\n",
    "    fs.rm(ent_merged_folder, recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ent_df.to_parquet(ent_merged_folder, engine=\"pyarrow\", compression=\"snappy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.du(ent_merged_folder) / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_df = dd.read_parquet(ent_merged_folder, engine=\"pyarrow\")\n",
    "ent_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ent_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entities(8): RxNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 8\n",
    "ent_full_folder = ENT_FULL_FOLDER_T.format(MODEL_NAMES[i])\n",
    "ent_inc_folder = ENT_INC_FOLDER_T.format(MODEL_NAMES[i])\n",
    "ent_merged_folder = ENT_MERGED_FOLDER_T.format(MODEL_NAMES[i])\n",
    "\n",
    "print(\"Input: {:s}\".format(ent_full_folder))\n",
    "print(\"Incremental: {:s}\".format(ent_inc_folder))\n",
    "print(\"Merged: {:s}\".format(ent_merged_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_full_df = dd.read_parquet(ent_full_folder, engine=\"pyarrow\")\n",
    "ent_inc_df = dd.read_parquet(ent_inc_folder, engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_df = delete_diff_rows(ent_full_df, del_df)\n",
    "ent_df = add_diff_rows(ent_df, ent_inc_df)\n",
    "ent_df = set_entity_dtypes(ent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fs.exists(ent_merged_folder):\n",
    "    fs.rm(ent_merged_folder, recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ent_df.to_parquet(ent_merged_folder, engine=\"pyarrow\", compression=\"snappy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.du(ent_merged_folder) / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_df = dd.read_parquet(ent_merged_folder, engine=\"pyarrow\")\n",
    "ent_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ent_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do this if youre done using the cluster\n",
    "# cluster.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
